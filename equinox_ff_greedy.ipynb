{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_XAvDyoFkBRs",
    "outputId": "07d88b1a-2ae5-4cc3-93a0-f99f3e1f367a"
   },
   "outputs": [],
   "source": [
    "!pip install -q mnists equinox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1Um2-G6MkYwD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import equinox as eqx\n",
    "import optax\n",
    "from jaxtyping import Array, Float, Int, PyTree\n",
    "import jax.tree_util as jtu\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "id": "mwbJQVPdkpZw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mnists\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = mnists.MNIST()\n",
    "\n",
    "X_train = dataset.train_images().astype(np.float32)[:, None, :] / 255.0\n",
    "y_train = dataset.train_labels().astype(np.int32)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=0.1, random_state=0,\n",
    ")\n",
    "\n",
    "X_test = dataset.test_images().astype(np.float32)[:, None, :] / 255.0\n",
    "y_test = dataset.test_labels().astype(np.int32)\n",
    "\n",
    "BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AEPfHzMckvcQ",
    "outputId": "b703edbe-c3d5-400f-e9c5-7982483355e6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((512, 1, 28, 28), (512,), numpy.ndarray, 0)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def batch_data(*args, batch_size, enum=False, shorten=False):\n",
    "    assert shorten or all(len(x) == len(args[0]) for x in args)\n",
    "    n = min(len(x) for x in args)\n",
    "    for i in range(0, n, batch_size):\n",
    "        if enum:\n",
    "            yield (i, *(x[i:i+batch_size] for x in args))\n",
    "        else:\n",
    "            yield (x[i:i+batch_size] for x in args)\n",
    "\n",
    "_i, X_dummy, y_dummy = next(iter(batch_data(X_train, y_train, enum=True, batch_size=BATCH_SIZE)))\n",
    "X_dummy.shape, y_dummy.shape, type(X_dummy), _i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 779
    },
    "id": "HUMx9tVLlVLa",
    "outputId": "20863ff7-80d1-4aa6-82aa-4d66c66889af",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tiles(examples, title=\"\"):\n",
    "    rows_count = examples.shape[0]\n",
    "    cols_count = examples.shape[1]\n",
    "    tile_height = examples.shape[2]\n",
    "    tile_width = examples.shape[3]\n",
    "\n",
    "    space_between_tiles = 2\n",
    "    img_matrix = np.empty(shape=(rows_count * (tile_height + space_between_tiles) - space_between_tiles,\n",
    "                                 cols_count * (tile_width + space_between_tiles) - space_between_tiles))\n",
    "    img_matrix.fill(np.nan)\n",
    "\n",
    "    for r in range(rows_count):\n",
    "        for c in range(cols_count):\n",
    "            x_0 = r * (tile_height + space_between_tiles)\n",
    "            y_0 = c * (tile_width + space_between_tiles)\n",
    "            img_matrix[x_0:x_0 + tile_height, y_0:y_0 + tile_width] = examples[r, c]\n",
    "\n",
    "    plt.matshow(img_matrix, cmap='gray', interpolation='none')\n",
    "    plt.axis('off')\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 797
    },
    "id": "RopZEKv7k3wJ",
    "outputId": "857ec512-53b3-4181-e00a-4dfb8219d919",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54000, 1, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 437,
       "width": 392
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def jnp_encode_class_in_image(X, y, num_classes):\n",
    "    y = jnp.eye(num_classes)[y]\n",
    "    orig_shape = X.shape\n",
    "    X = X.reshape(X.shape[0], -1)\n",
    "    X = X.at[:, :num_classes].set(y)\n",
    "    X = X.reshape(orig_shape)\n",
    "    return X\n",
    "\n",
    "def np_encode_class_in_image(X, y, num_classes):\n",
    "    y = np.eye(num_classes)[y]\n",
    "    orig_shape = X.shape\n",
    "    X = X.copy()\n",
    "    X = X.reshape(X.shape[0], -1)\n",
    "    X[:, :num_classes] = y\n",
    "    X = X.reshape(orig_shape)\n",
    "    return X\n",
    "\n",
    "X_train_pos = np_encode_class_in_image(X_train, y_train, len(dataset.classes))\n",
    "\n",
    "print(X_train_pos.shape)\n",
    "tiles(X_train_pos[:16].reshape(4, 4, 28, 28), \"Positive data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GmeMqkYwk4ro",
    "outputId": "207c2b33-e315-4a44-ce19-4149a192ce2b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54000, 1, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 437,
       "width": 392
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def derange(y, rng, max_iters):\n",
    "    best_permuted_y = y\n",
    "    best_n_deranged = 0\n",
    "    for _ in range(max_iters):\n",
    "        permuted_y = rng.permutation(y)\n",
    "        n_deranged = (permuted_y != y).sum()\n",
    "        if n_deranged > best_n_deranged:\n",
    "            best_permuted_y = permuted_y\n",
    "            best_n_deranged = n_deranged\n",
    "    return permuted_y\n",
    "\n",
    "y_train_concat = np.concatenate([y_train, y_train])\n",
    "y_train_neg = derange(y_train_concat, np.random.default_rng(0), 10)  # more iters are not worth it\n",
    "\n",
    "# remove positive labels and adjust size\n",
    "neg_idxs = y_train_neg != y_train_concat  \n",
    "X_train_neg = np.concatenate([X_train, X_train])[neg_idxs]\n",
    "X_train_neg = X_train_neg[:len(X_train)]\n",
    "y_train_neg = y_train_neg[neg_idxs]\n",
    "y_train_neg = y_train_neg[:len(y_train)]\n",
    "X_train_neg = np_encode_class_in_image(X_train_neg, y_train_neg, len(dataset.classes))\n",
    "del y_train_neg\n",
    "\n",
    "print(X_train_neg.shape)\n",
    "tiles(X_train_neg[:16].reshape(4, 4, 28, 28), \"Negative data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NORMALIZATION_OFFSET = 1e-4\n",
    "\n",
    "def normalize(x):\n",
    "    return x / (jnp.linalg.norm(x) + NORMALIZATION_OFFSET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EJql_sjpD3lz",
    "outputId": "b20dbe60-c083-4085-d5fa-33fbfc4c3ae2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "(512, 10)\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "class FFLayer(eqx.Module):\n",
    "    layers: list\n",
    "\n",
    "    def __init__(self, *layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "class FFNetwork(eqx.Module):\n",
    "    layers: list\n",
    "\n",
    "    def __init__(self, key):\n",
    "        keys = jax.random.split(key, 5)\n",
    "        self.layers = [\n",
    "            FFLayer(\n",
    "                normalize,\n",
    "                jnp.ravel,\n",
    "                eqx.nn.Linear(784, 512, key=keys[2]),\n",
    "                jax.nn.relu,\n",
    "            ),\n",
    "            FFLayer(\n",
    "                normalize,\n",
    "                eqx.nn.Linear(512, 512, key=keys[3]),\n",
    "                jax.nn.relu,\n",
    "            ),\n",
    "            FFLayer(\n",
    "                normalize,\n",
    "                eqx.nn.Linear(512, 10, key=keys[3]),\n",
    "                jax.nn.relu,\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "    def __call__(self, x: Float[Array, \"1 28 28\"]) -> Float[Array, \"500\"]:\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "model = FFNetwork(jax.random.PRNGKey(0))\n",
    "print(model(X_dummy[0]).shape)\n",
    "print(eqx.filter_vmap(model)(X_dummy).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def goodness_fn(x: Float[Array, \"batch ...\"]) -> Float[Array, \"batch\"]:\n",
    "    return (x * x).reshape(x.shape[0], -1).mean(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HMHyt34GNFHR",
    "outputId": "ad5579bc-2d39-4626-c52c-e1844e152a41",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12697868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array(2.1265538, dtype=float32)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@eqx.filter_jit\n",
    "def loss_and_outputs(\n",
    "    layer: FFLayer,\n",
    "    x: Float[Array, \"batch ...\"],\n",
    "    sgn: float,\n",
    "    threshold: float,\n",
    ") -> tuple[Float[Array, \"\"], Float[Array, \"batch ...\"]]:\n",
    "    x = jax.vmap(layer)(x)\n",
    "    g = sgn * (goodness_fn(x) - threshold)\n",
    "    # g = jax.nn.sigmoid(g).mean()\n",
    "    g = jax.nn.softplus(g).mean()\n",
    "    return g, x\n",
    "\n",
    "print(loss_and_outputs(model.layers[0], X_dummy, sgn=1, threshold=2)[0])\n",
    "loss_and_outputs(model.layers[0], X_dummy, sgn=-1, threshold=2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1265538 (512, 512)\n",
      "2.1262922 (512, 512)\n",
      "2.1252146 (512, 10)\n"
     ]
    }
   ],
   "source": [
    "x = X_dummy\n",
    "\n",
    "for layer in model.layers:\n",
    "    loss_val, x = loss_and_outputs(layer, x, sgn=-1, threshold=2)\n",
    "    print(loss_val, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WCcaITOc1AbB",
    "outputId": "d13b8294-49bb-4e1b-f206-c52e24bb1bd8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class '__main__.FFLayer'>, <class 'jaxlib.xla_extension.ArrayImpl'>]\n",
      "[<class 'tuple'>, <class '__main__.FFLayer'>]\n"
     ]
    }
   ],
   "source": [
    "print(list(map(type, \n",
    "    eqx.filter_grad(loss_and_outputs, has_aux=True)(\n",
    "        model.layers[0], X_dummy, sgn=-1, threshold=5\n",
    "    )\n",
    ")))\n",
    "print(list(map(type,\n",
    "    eqx.filter_value_and_grad(loss_and_outputs, has_aux=True)(\n",
    "        model.layers[0], X_dummy, sgn=-1, threshold=2\n",
    "    )\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "id": "p13pzSSIyS1H",
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2V4f2DMvfVt8",
    "outputId": "2dbc5b84-c55a-4103-fb85-eabe53ee4b1c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 10)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@eqx.filter_jit\n",
    "def predict(\n",
    "    model: FFNetwork,\n",
    "    x: Float[Array, \"batch 1 28 28\"],\n",
    "    upto_layer = None, \n",
    "    num_classes: int = NUM_CLASSES,\n",
    ") -> Float[Array, \"batch num_classes\"]:\n",
    "    preds = jnp.zeros((x.shape[0], num_classes))\n",
    "    layers = list(map(eqx.filter_vmap, model.layers))\n",
    "\n",
    "    for label in jnp.arange(num_classes):\n",
    "        t = jnp_encode_class_in_image(x, label, num_classes)\n",
    "        t = layers[0](t)\n",
    "\n",
    "        goodness = 0\n",
    "        for layer in layers[1:upto_layer]:\n",
    "            t = layer(t)\n",
    "            goodness += goodness_fn(t)\n",
    "        preds = preds.at[:, label].set(goodness)\n",
    "\n",
    "    return preds\n",
    "\n",
    "predict(model, X_dummy).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 10)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def batch_predict(model, X, batch_size, num_classes=NUM_CLASSES):\n",
    "    preds = jnp.zeros((X.shape[0], num_classes))\n",
    "\n",
    "    for i, x in batch_data(X, batch_size=batch_size, enum=True):\n",
    "        batch_preds = predict(model, x, num_classes)\n",
    "        preds = preds.at[i:i+batch_size].set(batch_preds)\n",
    "\n",
    "    return preds\n",
    "\n",
    "batch_predict(model, X_valid, BATCH_SIZE).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "trSTBI5wdNpG",
    "outputId": "88ed1ab7-e468-4ca8-bb62-f027d10edfe6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.1015625, dtype=float32)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_accuracy(model, x, y, upto_layer=None, num_classes=NUM_CLASSES):\n",
    "    preds = predict(model, x, upto_layer=upto_layer, num_classes=num_classes)\n",
    "    pred_y = jax.nn.softmax(preds, axis=-1).argmax(axis=-1)\n",
    "    return jnp.mean(y == pred_y)\n",
    "\n",
    "compute_accuracy(model, X_dummy, y_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I_z2HA7XUwQQ",
    "outputId": "6860137c-d196-452b-906a-5b60e40993d7",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(0.00273464, dtype=float32), Array(0.0756721, dtype=float32))"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate(model, X_test, y_test, batch_size, upto_layer=None, num_classes=NUM_CLASSES):\n",
    "    avg_accuracy = 0\n",
    "    avg_goodness = 0\n",
    "    n_batches = (len(X_test) + batch_size - 1) // batch_size\n",
    "\n",
    "    for x, y in batch_data(X_test, y_test, batch_size=batch_size):\n",
    "        preds = predict(model, x, upto_layer, num_classes)\n",
    "        pred_y = jax.nn.softmax(preds, axis=-1).argmax(axis=-1)\n",
    "        goodness = preds[jnp.arange(preds.shape[0]), pred_y]\n",
    "        avg_goodness += goodness.mean()\n",
    "        avg_accuracy += jnp.mean(y == pred_y)\n",
    "\n",
    "    avg_goodness /= n_batches\n",
    "    avg_accuracy /= n_batches\n",
    "    return avg_goodness, avg_accuracy\n",
    "\n",
    "evaluate(model, X_test, y_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "id": "eqRdq64qZwfB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def train(\n",
    "    model: FFNetwork,\n",
    "    optims: list[optax.GradientTransformation],\n",
    "    opt_states,\n",
    "    *,\n",
    "    threshold: float,\n",
    "    batch_size: int,\n",
    "    epochs: int,\n",
    "    print_every: int, \n",
    "    metrics,\n",
    "):\n",
    "    n_batches = (len(X_train) + batch_size - 1) // batch_size\n",
    "    metrics = deepcopy(metrics)\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def make_substep(layer, opt_state, optim, x, sgn):\n",
    "        grads, x = eqx.filter_grad(loss_and_outputs, has_aux=True)(\n",
    "            layer, x, sgn=sgn, threshold=threshold\n",
    "        )\n",
    "        updates, opt_state = optim.update(grads, opt_state, layer)\n",
    "        layer = eqx.apply_updates(layer, updates)\n",
    "\n",
    "        return layer, opt_state, x\n",
    "\n",
    "    def make_step(model, opt_states, x_pos, x_neg):\n",
    "        pos_goodness = neg_goodness = 0\n",
    "        \n",
    "        for i, (layer, opt_state, optim) in enumerate(zip(model.layers, opt_states, optims)):\n",
    "            layer, opt_state, x_pos = make_substep(layer, opt_state, optim, x_pos, sgn=-1.)\n",
    "            layer, opt_state, x_neg = make_substep(layer, opt_state, optim, x_neg, sgn=1.)\n",
    "\n",
    "            model = eqx.tree_at(lambda m: m.layers[i], model, layer)\n",
    "            opt_states = eqx.tree_at(lambda o: o[i], opt_states, opt_state)\n",
    "\n",
    "            pos_goodness += goodness_fn(x_pos).mean()\n",
    "            neg_goodness += goodness_fn(x_neg).mean()\n",
    "\n",
    "        return model, opt_states, pos_goodness, neg_goodness\n",
    "\n",
    "\n",
    "    try:\n",
    "        for epoch in range(epochs):\n",
    "            avg_pos_goodness = avg_neg_goodness = 0\n",
    "\n",
    "            for x_pos, x_neg in batch_data(\n",
    "                X_train_pos, X_train_neg, \n",
    "                shorten=True, batch_size=batch_size\n",
    "            ):\n",
    "                model, opt_states, pos_goodness, neg_goodness = make_step(\n",
    "                    model, opt_states, x_pos, x_neg\n",
    "                )\n",
    "\n",
    "                avg_pos_goodness += pos_goodness\n",
    "                avg_neg_goodness += neg_goodness\n",
    "\n",
    "            avg_pos_goodness = avg_pos_goodness.item() / n_batches\n",
    "            avg_neg_goodness = avg_neg_goodness.item() / n_batches\n",
    "            metrics[\"pos_goodness\"].append(avg_pos_goodness)\n",
    "            metrics[\"neg_goodness\"].append(avg_neg_goodness)\n",
    "\n",
    "            if (epoch + 1) % print_every == 0:\n",
    "                valid_goodness, valid_accuracy = evaluate(model, X_valid, y_valid, batch_size)\n",
    "                metrics[\"valid_goodness\"].append(valid_goodness.item())\n",
    "                metrics[\"valid_accuracy\"].append(valid_accuracy.item())\n",
    "                print(\n",
    "                    f\"[{epoch + 1:3d}] train_pos_goodness={avg_pos_goodness:10.3f} \"\n",
    "                    f\"train_neg_goodness={avg_neg_goodness:10.3f} \"\n",
    "                    f\"valid_goodness={valid_goodness:10.3f} \"\n",
    "                    f\"valid_accuracy={valid_accuracy:8.5f} \"\n",
    "                )\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    return model, opt_states, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_greedy(\n",
    "    model: FFNetwork,\n",
    "    optims: list[optax.GradientTransformation],\n",
    "    opt_states,\n",
    "    *,\n",
    "    threshold: float,\n",
    "    batch_size: int,\n",
    "    epochs: int,\n",
    "    print_every: int, \n",
    "    metrics,\n",
    "):\n",
    "    n_batches = (len(X_train) + batch_size - 1) // batch_size\n",
    "    metrics = deepcopy(metrics)\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def make_step(layer, opt_state, optim, x, sgn):\n",
    "        grads, x = eqx.filter_grad(loss_and_outputs, has_aux=True)(\n",
    "            layer, x, sgn=sgn, threshold=threshold\n",
    "        )\n",
    "        updates, opt_state = optim.update(grads, opt_state, layer)\n",
    "        layer = eqx.apply_updates(layer, updates)\n",
    "\n",
    "        return layer, opt_state, x\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def forward_prev_layers(model, upto_layer, x):\n",
    "        for layer in model.layers[:upto_layer]:\n",
    "            x = eqx.filter_vmap(layer)(x)\n",
    "        return x\n",
    "    \n",
    "    try:\n",
    "        for i, (layer, opt_state, optim) in enumerate(zip(model.layers, opt_states, optims)):\n",
    "            for epoch in range(epochs):\n",
    "                pos_goodness = neg_goodness = 0\n",
    "\n",
    "                for x_pos, x_neg in batch_data(\n",
    "                    X_train_pos, X_train_neg, \n",
    "                    shorten=True, batch_size=batch_size\n",
    "                ):\n",
    "                    # for prev_layer in model.layers[:i]:\n",
    "                    x_pos = forward_prev_layers(model, i, x_pos)\n",
    "                    x_neg = forward_prev_layers(model, i, x_neg)\n",
    "\n",
    "                    layer, opt_state, x_pos = make_step(layer, opt_state, optim, x_pos, sgn=-1.)\n",
    "                    layer, opt_state, x_neg = make_step(layer, opt_state, optim, x_neg, sgn=1.)\n",
    "\n",
    "                    model = eqx.tree_at(lambda m: m.layers[i], model, layer)\n",
    "                    opt_states = eqx.tree_at(lambda o: o[i], opt_states, opt_state)\n",
    "                        \n",
    "                    pos_goodness += goodness_fn(x_pos).mean()\n",
    "                    neg_goodness += goodness_fn(x_neg).mean()\n",
    "\n",
    "                avg_pos_goodness = pos_goodness.item() / n_batches\n",
    "                avg_neg_goodness = neg_goodness.item() / n_batches\n",
    "\n",
    "                if (epoch + 1) % print_every == 0:\n",
    "                    # valid_goodness, valid_accuracy = evaluate(model, X_valid, y_valid, i+1, batch_size)\n",
    "                    print(\n",
    "                        f\"[Layer: {i}] [{epoch + 1:3d}] train_pos_goodness={avg_pos_goodness:10.3f} \"\n",
    "                        f\"train_neg_goodness={avg_neg_goodness:10.3f} \"\n",
    "                        # f\"valid_goodness={valid_goodness:10.3f} \"\n",
    "                        # f\"valid_accuracy={valid_accuracy:8.5f} \"\n",
    "                    )\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    return model, opt_states, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 3.\n",
    "BATCH_SIZE = 512\n",
    "LEARNING_RATE = 0.03\n",
    "EPOCHS = 100\n",
    "PRINT_EVERY = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "5uZe_WQnDPds",
    "outputId": "08221f30-d4c7-4ea2-e287-80a10e031d19",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Layer: 0] [  1] train_pos_goodness=     2.779 train_neg_goodness=     2.840 \n",
      "[Layer: 0] [  2] train_pos_goodness=     2.947 train_neg_goodness=     2.921 \n",
      "[Layer: 0] [  3] train_pos_goodness=     3.035 train_neg_goodness=     2.882 \n",
      "[Layer: 0] [  4] train_pos_goodness=     3.157 train_neg_goodness=     2.808 \n",
      "[Layer: 0] [  5] train_pos_goodness=     3.296 train_neg_goodness=     2.716 \n",
      "[Layer: 0] [  6] train_pos_goodness=     3.426 train_neg_goodness=     2.630 \n",
      "[Layer: 0] [  7] train_pos_goodness=     3.544 train_neg_goodness=     2.548 \n",
      "[Layer: 0] [  8] train_pos_goodness=     3.657 train_neg_goodness=     2.467 \n",
      "[Layer: 0] [  9] train_pos_goodness=     3.764 train_neg_goodness=     2.389 \n",
      "[Layer: 0] [ 10] train_pos_goodness=     3.867 train_neg_goodness=     2.316 \n",
      "[Layer: 0] [ 11] train_pos_goodness=     3.964 train_neg_goodness=     2.246 \n",
      "[Layer: 0] [ 12] train_pos_goodness=     4.055 train_neg_goodness=     2.180 \n",
      "[Layer: 0] [ 13] train_pos_goodness=     4.142 train_neg_goodness=     2.118 \n",
      "[Layer: 0] [ 14] train_pos_goodness=     4.225 train_neg_goodness=     2.060 \n",
      "[Layer: 0] [ 15] train_pos_goodness=     4.305 train_neg_goodness=     2.005 \n",
      "[Layer: 0] [ 16] train_pos_goodness=     4.381 train_neg_goodness=     1.954 \n",
      "[Layer: 0] [ 17] train_pos_goodness=     4.456 train_neg_goodness=     1.906 \n",
      "[Layer: 0] [ 18] train_pos_goodness=     4.529 train_neg_goodness=     1.860 \n",
      "[Layer: 0] [ 19] train_pos_goodness=     4.600 train_neg_goodness=     1.817 \n",
      "[Layer: 0] [ 20] train_pos_goodness=     4.671 train_neg_goodness=     1.775 \n",
      "[Layer: 0] [ 21] train_pos_goodness=     4.741 train_neg_goodness=     1.736 \n",
      "[Layer: 0] [ 22] train_pos_goodness=     4.810 train_neg_goodness=     1.698 \n",
      "[Layer: 0] [ 23] train_pos_goodness=     4.879 train_neg_goodness=     1.662 \n",
      "[Layer: 0] [ 24] train_pos_goodness=     4.947 train_neg_goodness=     1.627 \n",
      "[Layer: 0] [ 25] train_pos_goodness=     5.015 train_neg_goodness=     1.594 \n",
      "[Layer: 0] [ 26] train_pos_goodness=     5.082 train_neg_goodness=     1.562 \n",
      "[Layer: 0] [ 27] train_pos_goodness=     5.149 train_neg_goodness=     1.531 \n",
      "[Layer: 0] [ 28] train_pos_goodness=     5.216 train_neg_goodness=     1.501 \n",
      "[Layer: 0] [ 29] train_pos_goodness=     5.283 train_neg_goodness=     1.471 \n",
      "[Layer: 0] [ 30] train_pos_goodness=     5.350 train_neg_goodness=     1.443 \n",
      "[Layer: 0] [ 31] train_pos_goodness=     5.416 train_neg_goodness=     1.415 \n",
      "[Layer: 0] [ 32] train_pos_goodness=     5.482 train_neg_goodness=     1.388 \n",
      "[Layer: 0] [ 33] train_pos_goodness=     5.547 train_neg_goodness=     1.361 \n",
      "[Layer: 0] [ 34] train_pos_goodness=     5.613 train_neg_goodness=     1.335 \n",
      "[Layer: 0] [ 35] train_pos_goodness=     5.678 train_neg_goodness=     1.309 \n",
      "[Layer: 0] [ 36] train_pos_goodness=     5.743 train_neg_goodness=     1.284 \n",
      "[Layer: 0] [ 37] train_pos_goodness=     5.808 train_neg_goodness=     1.260 \n",
      "[Layer: 0] [ 38] train_pos_goodness=     5.872 train_neg_goodness=     1.235 \n",
      "[Layer: 0] [ 39] train_pos_goodness=     5.937 train_neg_goodness=     1.211 \n",
      "[Layer: 0] [ 40] train_pos_goodness=     6.002 train_neg_goodness=     1.187 \n",
      "[Layer: 0] [ 41] train_pos_goodness=     6.066 train_neg_goodness=     1.164 \n",
      "[Layer: 0] [ 42] train_pos_goodness=     6.131 train_neg_goodness=     1.141 \n",
      "[Layer: 0] [ 43] train_pos_goodness=     6.195 train_neg_goodness=     1.118 \n",
      "[Layer: 0] [ 44] train_pos_goodness=     6.260 train_neg_goodness=     1.095 \n",
      "[Layer: 0] [ 45] train_pos_goodness=     6.325 train_neg_goodness=     1.073 \n",
      "[Layer: 0] [ 46] train_pos_goodness=     6.391 train_neg_goodness=     1.051 \n",
      "[Layer: 0] [ 47] train_pos_goodness=     6.457 train_neg_goodness=     1.029 \n",
      "[Layer: 0] [ 48] train_pos_goodness=     6.523 train_neg_goodness=     1.008 \n",
      "[Layer: 0] [ 49] train_pos_goodness=     6.590 train_neg_goodness=     0.987 \n",
      "[Layer: 0] [ 50] train_pos_goodness=     6.657 train_neg_goodness=     0.966 \n",
      "[Layer: 0] [ 51] train_pos_goodness=     6.724 train_neg_goodness=     0.946 \n",
      "[Layer: 0] [ 52] train_pos_goodness=     6.792 train_neg_goodness=     0.926 \n",
      "[Layer: 0] [ 53] train_pos_goodness=     6.860 train_neg_goodness=     0.906 \n",
      "[Layer: 0] [ 54] train_pos_goodness=     6.928 train_neg_goodness=     0.887 \n",
      "[Layer: 0] [ 55] train_pos_goodness=     6.997 train_neg_goodness=     0.868 \n",
      "[Layer: 0] [ 56] train_pos_goodness=     7.065 train_neg_goodness=     0.850 \n",
      "[Layer: 0] [ 57] train_pos_goodness=     7.133 train_neg_goodness=     0.832 \n",
      "[Layer: 0] [ 58] train_pos_goodness=     7.202 train_neg_goodness=     0.815 \n",
      "[Layer: 0] [ 59] train_pos_goodness=     7.270 train_neg_goodness=     0.797 \n",
      "[Layer: 0] [ 60] train_pos_goodness=     7.339 train_neg_goodness=     0.780 \n",
      "[Layer: 0] [ 61] train_pos_goodness=     7.407 train_neg_goodness=     0.764 \n",
      "[Layer: 0] [ 62] train_pos_goodness=     7.475 train_neg_goodness=     0.748 \n",
      "[Layer: 0] [ 63] train_pos_goodness=     7.543 train_neg_goodness=     0.732 \n",
      "[Layer: 0] [ 64] train_pos_goodness=     7.611 train_neg_goodness=     0.716 \n",
      "[Layer: 0] [ 65] train_pos_goodness=     7.680 train_neg_goodness=     0.701 \n",
      "[Layer: 0] [ 66] train_pos_goodness=     7.748 train_neg_goodness=     0.686 \n",
      "[Layer: 0] [ 67] train_pos_goodness=     7.816 train_neg_goodness=     0.672 \n",
      "[Layer: 0] [ 68] train_pos_goodness=     7.884 train_neg_goodness=     0.658 \n",
      "[Layer: 0] [ 69] train_pos_goodness=     7.951 train_neg_goodness=     0.644 \n",
      "[Layer: 0] [ 70] train_pos_goodness=     8.019 train_neg_goodness=     0.631 \n",
      "[Layer: 0] [ 71] train_pos_goodness=     8.086 train_neg_goodness=     0.618 \n",
      "[Layer: 0] [ 72] train_pos_goodness=     8.154 train_neg_goodness=     0.605 \n",
      "[Layer: 0] [ 73] train_pos_goodness=     8.221 train_neg_goodness=     0.593 \n",
      "[Layer: 0] [ 74] train_pos_goodness=     8.288 train_neg_goodness=     0.581 \n",
      "[Layer: 0] [ 75] train_pos_goodness=     8.354 train_neg_goodness=     0.569 \n",
      "[Layer: 0] [ 76] train_pos_goodness=     8.421 train_neg_goodness=     0.558 \n",
      "[Layer: 0] [ 77] train_pos_goodness=     8.487 train_neg_goodness=     0.547 \n",
      "[Layer: 0] [ 78] train_pos_goodness=     8.553 train_neg_goodness=     0.537 \n",
      "[Layer: 0] [ 79] train_pos_goodness=     8.619 train_neg_goodness=     0.526 \n",
      "[Layer: 0] [ 80] train_pos_goodness=     8.684 train_neg_goodness=     0.516 \n",
      "[Layer: 0] [ 81] train_pos_goodness=     8.749 train_neg_goodness=     0.507 \n",
      "[Layer: 0] [ 82] train_pos_goodness=     8.814 train_neg_goodness=     0.497 \n",
      "[Layer: 0] [ 83] train_pos_goodness=     8.878 train_neg_goodness=     0.488 \n",
      "[Layer: 0] [ 84] train_pos_goodness=     8.942 train_neg_goodness=     0.479 \n",
      "[Layer: 0] [ 85] train_pos_goodness=     9.005 train_neg_goodness=     0.471 \n",
      "[Layer: 0] [ 86] train_pos_goodness=     9.068 train_neg_goodness=     0.462 \n",
      "[Layer: 0] [ 87] train_pos_goodness=     9.131 train_neg_goodness=     0.454 \n",
      "[Layer: 0] [ 88] train_pos_goodness=     9.194 train_neg_goodness=     0.446 \n",
      "[Layer: 0] [ 89] train_pos_goodness=     9.256 train_neg_goodness=     0.438 \n",
      "[Layer: 0] [ 90] train_pos_goodness=     9.317 train_neg_goodness=     0.431 \n",
      "[Layer: 0] [ 91] train_pos_goodness=     9.379 train_neg_goodness=     0.424 \n",
      "[Layer: 0] [ 92] train_pos_goodness=     9.440 train_neg_goodness=     0.416 \n",
      "[Layer: 0] [ 93] train_pos_goodness=     9.500 train_neg_goodness=     0.409 \n",
      "[Layer: 0] [ 94] train_pos_goodness=     9.560 train_neg_goodness=     0.403 \n",
      "[Layer: 0] [ 95] train_pos_goodness=     9.620 train_neg_goodness=     0.396 \n",
      "[Layer: 0] [ 96] train_pos_goodness=     9.679 train_neg_goodness=     0.390 \n",
      "[Layer: 0] [ 97] train_pos_goodness=     9.738 train_neg_goodness=     0.383 \n",
      "[Layer: 0] [ 98] train_pos_goodness=     9.797 train_neg_goodness=     0.377 \n",
      "[Layer: 0] [ 99] train_pos_goodness=     9.855 train_neg_goodness=     0.371 \n",
      "[Layer: 0] [100] train_pos_goodness=     9.912 train_neg_goodness=     0.366 \n",
      "[Layer: 1] [  1] train_pos_goodness=     4.757 train_neg_goodness=     1.458 \n",
      "[Layer: 1] [  2] train_pos_goodness=     5.448 train_neg_goodness=     1.237 \n",
      "[Layer: 1] [  3] train_pos_goodness=     5.706 train_neg_goodness=     1.092 \n",
      "[Layer: 1] [  4] train_pos_goodness=     5.884 train_neg_goodness=     1.009 \n",
      "[Layer: 1] [  5] train_pos_goodness=     6.017 train_neg_goodness=     0.952 \n",
      "[Layer: 1] [  6] train_pos_goodness=     6.124 train_neg_goodness=     0.908 \n",
      "[Layer: 1] [  7] train_pos_goodness=     6.215 train_neg_goodness=     0.872 \n",
      "[Layer: 1] [  8] train_pos_goodness=     6.296 train_neg_goodness=     0.842 \n",
      "[Layer: 1] [  9] train_pos_goodness=     6.368 train_neg_goodness=     0.817 \n",
      "[Layer: 1] [ 10] train_pos_goodness=     6.433 train_neg_goodness=     0.795 \n",
      "[Layer: 1] [ 11] train_pos_goodness=     6.493 train_neg_goodness=     0.775 \n",
      "[Layer: 1] [ 12] train_pos_goodness=     6.548 train_neg_goodness=     0.758 \n",
      "[Layer: 1] [ 13] train_pos_goodness=     6.600 train_neg_goodness=     0.742 \n",
      "[Layer: 1] [ 14] train_pos_goodness=     6.649 train_neg_goodness=     0.728 \n",
      "[Layer: 1] [ 15] train_pos_goodness=     6.695 train_neg_goodness=     0.715 \n",
      "[Layer: 1] [ 16] train_pos_goodness=     6.738 train_neg_goodness=     0.703 \n",
      "[Layer: 1] [ 17] train_pos_goodness=     6.779 train_neg_goodness=     0.691 \n",
      "[Layer: 1] [ 18] train_pos_goodness=     6.817 train_neg_goodness=     0.681 \n",
      "[Layer: 1] [ 19] train_pos_goodness=     6.854 train_neg_goodness=     0.671 \n",
      "[Layer: 1] [ 20] train_pos_goodness=     6.888 train_neg_goodness=     0.661 \n",
      "[Layer: 1] [ 21] train_pos_goodness=     6.921 train_neg_goodness=     0.653 \n",
      "[Layer: 1] [ 22] train_pos_goodness=     6.952 train_neg_goodness=     0.644 \n",
      "[Layer: 1] [ 23] train_pos_goodness=     6.981 train_neg_goodness=     0.636 \n",
      "[Layer: 1] [ 24] train_pos_goodness=     7.010 train_neg_goodness=     0.629 \n",
      "[Layer: 1] [ 25] train_pos_goodness=     7.038 train_neg_goodness=     0.621 \n",
      "[Layer: 1] [ 26] train_pos_goodness=     7.065 train_neg_goodness=     0.614 \n",
      "[Layer: 1] [ 27] train_pos_goodness=     7.091 train_neg_goodness=     0.608 \n",
      "[Layer: 1] [ 28] train_pos_goodness=     7.117 train_neg_goodness=     0.602 \n",
      "[Layer: 1] [ 29] train_pos_goodness=     7.142 train_neg_goodness=     0.596 \n",
      "[Layer: 1] [ 30] train_pos_goodness=     7.167 train_neg_goodness=     0.590 \n",
      "[Layer: 1] [ 31] train_pos_goodness=     7.191 train_neg_goodness=     0.584 \n",
      "[Layer: 1] [ 32] train_pos_goodness=     7.214 train_neg_goodness=     0.579 \n",
      "[Layer: 1] [ 33] train_pos_goodness=     7.237 train_neg_goodness=     0.574 \n",
      "[Layer: 1] [ 34] train_pos_goodness=     7.260 train_neg_goodness=     0.569 \n",
      "[Layer: 1] [ 35] train_pos_goodness=     7.282 train_neg_goodness=     0.564 \n",
      "[Layer: 1] [ 36] train_pos_goodness=     7.304 train_neg_goodness=     0.560 \n",
      "[Layer: 1] [ 37] train_pos_goodness=     7.326 train_neg_goodness=     0.555 \n",
      "[Layer: 1] [ 38] train_pos_goodness=     7.347 train_neg_goodness=     0.551 \n",
      "[Layer: 1] [ 39] train_pos_goodness=     7.368 train_neg_goodness=     0.547 \n",
      "[Layer: 1] [ 40] train_pos_goodness=     7.389 train_neg_goodness=     0.543 \n",
      "[Layer: 1] [ 41] train_pos_goodness=     7.409 train_neg_goodness=     0.539 \n",
      "[Layer: 1] [ 42] train_pos_goodness=     7.430 train_neg_goodness=     0.536 \n",
      "[Layer: 1] [ 43] train_pos_goodness=     7.450 train_neg_goodness=     0.532 \n",
      "[Layer: 1] [ 44] train_pos_goodness=     7.470 train_neg_goodness=     0.529 \n",
      "[Layer: 1] [ 45] train_pos_goodness=     7.489 train_neg_goodness=     0.525 \n",
      "[Layer: 1] [ 46] train_pos_goodness=     7.509 train_neg_goodness=     0.522 \n",
      "[Layer: 1] [ 47] train_pos_goodness=     7.528 train_neg_goodness=     0.519 \n",
      "[Layer: 1] [ 48] train_pos_goodness=     7.546 train_neg_goodness=     0.516 \n",
      "[Layer: 1] [ 49] train_pos_goodness=     7.565 train_neg_goodness=     0.513 \n",
      "[Layer: 1] [ 50] train_pos_goodness=     7.583 train_neg_goodness=     0.510 \n",
      "[Layer: 1] [ 51] train_pos_goodness=     7.601 train_neg_goodness=     0.507 \n",
      "[Layer: 1] [ 52] train_pos_goodness=     7.618 train_neg_goodness=     0.504 \n",
      "[Layer: 1] [ 53] train_pos_goodness=     7.636 train_neg_goodness=     0.502 \n",
      "[Layer: 1] [ 54] train_pos_goodness=     7.653 train_neg_goodness=     0.499 \n",
      "[Layer: 1] [ 55] train_pos_goodness=     7.670 train_neg_goodness=     0.496 \n",
      "[Layer: 1] [ 56] train_pos_goodness=     7.687 train_neg_goodness=     0.494 \n",
      "[Layer: 1] [ 57] train_pos_goodness=     7.703 train_neg_goodness=     0.491 \n",
      "[Layer: 1] [ 58] train_pos_goodness=     7.720 train_neg_goodness=     0.489 \n",
      "[Layer: 1] [ 59] train_pos_goodness=     7.736 train_neg_goodness=     0.487 \n",
      "[Layer: 1] [ 60] train_pos_goodness=     7.752 train_neg_goodness=     0.484 \n",
      "[Layer: 1] [ 61] train_pos_goodness=     7.768 train_neg_goodness=     0.482 \n",
      "[Layer: 1] [ 62] train_pos_goodness=     7.783 train_neg_goodness=     0.480 \n",
      "[Layer: 1] [ 63] train_pos_goodness=     7.799 train_neg_goodness=     0.478 \n",
      "[Layer: 1] [ 64] train_pos_goodness=     7.814 train_neg_goodness=     0.476 \n",
      "[Layer: 1] [ 65] train_pos_goodness=     7.830 train_neg_goodness=     0.474 \n",
      "[Layer: 1] [ 66] train_pos_goodness=     7.845 train_neg_goodness=     0.472 \n",
      "[Layer: 1] [ 67] train_pos_goodness=     7.860 train_neg_goodness=     0.470 \n",
      "[Layer: 1] [ 68] train_pos_goodness=     7.875 train_neg_goodness=     0.468 \n",
      "[Layer: 1] [ 69] train_pos_goodness=     7.890 train_neg_goodness=     0.466 \n",
      "[Layer: 1] [ 70] train_pos_goodness=     7.904 train_neg_goodness=     0.464 \n",
      "[Layer: 1] [ 71] train_pos_goodness=     7.919 train_neg_goodness=     0.462 \n",
      "[Layer: 1] [ 72] train_pos_goodness=     7.933 train_neg_goodness=     0.460 \n",
      "[Layer: 1] [ 73] train_pos_goodness=     7.947 train_neg_goodness=     0.458 \n",
      "[Layer: 1] [ 74] train_pos_goodness=     7.961 train_neg_goodness=     0.456 \n",
      "[Layer: 1] [ 75] train_pos_goodness=     7.975 train_neg_goodness=     0.454 \n",
      "[Layer: 1] [ 76] train_pos_goodness=     7.989 train_neg_goodness=     0.453 \n",
      "[Layer: 1] [ 77] train_pos_goodness=     8.003 train_neg_goodness=     0.451 \n",
      "[Layer: 1] [ 78] train_pos_goodness=     8.016 train_neg_goodness=     0.449 \n",
      "[Layer: 1] [ 79] train_pos_goodness=     8.030 train_neg_goodness=     0.448 \n",
      "[Layer: 1] [ 80] train_pos_goodness=     8.043 train_neg_goodness=     0.446 \n",
      "[Layer: 1] [ 81] train_pos_goodness=     8.056 train_neg_goodness=     0.444 \n",
      "[Layer: 1] [ 82] train_pos_goodness=     8.069 train_neg_goodness=     0.443 \n",
      "[Layer: 1] [ 83] train_pos_goodness=     8.082 train_neg_goodness=     0.441 \n",
      "[Layer: 1] [ 84] train_pos_goodness=     8.095 train_neg_goodness=     0.440 \n",
      "[Layer: 1] [ 85] train_pos_goodness=     8.108 train_neg_goodness=     0.438 \n",
      "[Layer: 1] [ 86] train_pos_goodness=     8.121 train_neg_goodness=     0.436 \n",
      "[Layer: 1] [ 87] train_pos_goodness=     8.133 train_neg_goodness=     0.435 \n",
      "[Layer: 1] [ 88] train_pos_goodness=     8.146 train_neg_goodness=     0.433 \n",
      "[Layer: 1] [ 89] train_pos_goodness=     8.158 train_neg_goodness=     0.432 \n",
      "[Layer: 1] [ 90] train_pos_goodness=     8.171 train_neg_goodness=     0.430 \n",
      "[Layer: 1] [ 91] train_pos_goodness=     8.183 train_neg_goodness=     0.429 \n",
      "[Layer: 1] [ 92] train_pos_goodness=     8.195 train_neg_goodness=     0.428 \n",
      "[Layer: 1] [ 93] train_pos_goodness=     8.207 train_neg_goodness=     0.426 \n",
      "[Layer: 1] [ 94] train_pos_goodness=     8.220 train_neg_goodness=     0.425 \n",
      "[Layer: 1] [ 95] train_pos_goodness=     8.232 train_neg_goodness=     0.423 \n",
      "[Layer: 1] [ 96] train_pos_goodness=     8.244 train_neg_goodness=     0.422 \n",
      "[Layer: 1] [ 97] train_pos_goodness=     8.256 train_neg_goodness=     0.421 \n",
      "[Layer: 1] [ 98] train_pos_goodness=     8.268 train_neg_goodness=     0.419 \n",
      "[Layer: 1] [ 99] train_pos_goodness=     8.280 train_neg_goodness=     0.418 \n",
      "[Layer: 1] [100] train_pos_goodness=     8.292 train_neg_goodness=     0.417 \n",
      "[Layer: 2] [  1] train_pos_goodness=     5.922 train_neg_goodness=     0.963 \n",
      "[Layer: 2] [  2] train_pos_goodness=     6.143 train_neg_goodness=     0.768 \n",
      "[Layer: 2] [  3] train_pos_goodness=     6.310 train_neg_goodness=     0.675 \n",
      "[Layer: 2] [  4] train_pos_goodness=     6.435 train_neg_goodness=     0.618 \n",
      "[Layer: 2] [  5] train_pos_goodness=     6.535 train_neg_goodness=     0.579 \n",
      "[Layer: 2] [  6] train_pos_goodness=     6.618 train_neg_goodness=     0.550 \n",
      "[Layer: 2] [  7] train_pos_goodness=     6.689 train_neg_goodness=     0.528 \n",
      "[Layer: 2] [  8] train_pos_goodness=     6.749 train_neg_goodness=     0.510 \n",
      "[Layer: 2] [  9] train_pos_goodness=     6.799 train_neg_goodness=     0.496 \n",
      "[Layer: 2] [ 10] train_pos_goodness=     6.840 train_neg_goodness=     0.486 \n",
      "[Layer: 2] [ 11] train_pos_goodness=     6.872 train_neg_goodness=     0.477 \n",
      "[Layer: 2] [ 12] train_pos_goodness=     6.900 train_neg_goodness=     0.470 \n",
      "[Layer: 2] [ 13] train_pos_goodness=     6.927 train_neg_goodness=     0.464 \n",
      "[Layer: 2] [ 14] train_pos_goodness=     6.953 train_neg_goodness=     0.458 \n",
      "[Layer: 2] [ 15] train_pos_goodness=     6.979 train_neg_goodness=     0.453 \n",
      "[Layer: 2] [ 16] train_pos_goodness=     7.004 train_neg_goodness=     0.448 \n",
      "[Layer: 2] [ 17] train_pos_goodness=     7.027 train_neg_goodness=     0.444 \n",
      "[Layer: 2] [ 18] train_pos_goodness=     7.050 train_neg_goodness=     0.440 \n",
      "[Layer: 2] [ 19] train_pos_goodness=     7.071 train_neg_goodness=     0.436 \n",
      "[Layer: 2] [ 20] train_pos_goodness=     7.090 train_neg_goodness=     0.433 \n",
      "[Layer: 2] [ 21] train_pos_goodness=     7.109 train_neg_goodness=     0.430 \n",
      "[Layer: 2] [ 22] train_pos_goodness=     7.127 train_neg_goodness=     0.427 \n",
      "[Layer: 2] [ 23] train_pos_goodness=     7.145 train_neg_goodness=     0.424 \n",
      "[Layer: 2] [ 24] train_pos_goodness=     7.163 train_neg_goodness=     0.421 \n",
      "[Layer: 2] [ 25] train_pos_goodness=     7.180 train_neg_goodness=     0.418 \n",
      "[Layer: 2] [ 26] train_pos_goodness=     7.197 train_neg_goodness=     0.416 \n",
      "[Layer: 2] [ 27] train_pos_goodness=     7.213 train_neg_goodness=     0.414 \n",
      "[Layer: 2] [ 28] train_pos_goodness=     7.229 train_neg_goodness=     0.411 \n",
      "[Layer: 2] [ 29] train_pos_goodness=     7.245 train_neg_goodness=     0.409 \n",
      "[Layer: 2] [ 30] train_pos_goodness=     7.260 train_neg_goodness=     0.407 \n",
      "[Layer: 2] [ 31] train_pos_goodness=     7.275 train_neg_goodness=     0.405 \n",
      "[Layer: 2] [ 32] train_pos_goodness=     7.290 train_neg_goodness=     0.403 \n",
      "[Layer: 2] [ 33] train_pos_goodness=     7.305 train_neg_goodness=     0.401 \n",
      "[Layer: 2] [ 34] train_pos_goodness=     7.319 train_neg_goodness=     0.399 \n",
      "[Layer: 2] [ 35] train_pos_goodness=     7.334 train_neg_goodness=     0.398 \n",
      "[Layer: 2] [ 36] train_pos_goodness=     7.348 train_neg_goodness=     0.396 \n",
      "[Layer: 2] [ 37] train_pos_goodness=     7.362 train_neg_goodness=     0.394 \n",
      "[Layer: 2] [ 38] train_pos_goodness=     7.376 train_neg_goodness=     0.393 \n",
      "[Layer: 2] [ 39] train_pos_goodness=     7.390 train_neg_goodness=     0.391 \n",
      "[Layer: 2] [ 40] train_pos_goodness=     7.404 train_neg_goodness=     0.389 \n",
      "[Layer: 2] [ 41] train_pos_goodness=     7.418 train_neg_goodness=     0.388 \n",
      "[Layer: 2] [ 42] train_pos_goodness=     7.432 train_neg_goodness=     0.386 \n",
      "[Layer: 2] [ 43] train_pos_goodness=     7.446 train_neg_goodness=     0.384 \n",
      "[Layer: 2] [ 44] train_pos_goodness=     7.459 train_neg_goodness=     0.383 \n",
      "[Layer: 2] [ 45] train_pos_goodness=     7.473 train_neg_goodness=     0.381 \n",
      "[Layer: 2] [ 46] train_pos_goodness=     7.486 train_neg_goodness=     0.380 \n",
      "[Layer: 2] [ 47] train_pos_goodness=     7.500 train_neg_goodness=     0.378 \n",
      "[Layer: 2] [ 48] train_pos_goodness=     7.513 train_neg_goodness=     0.377 \n",
      "[Layer: 2] [ 49] train_pos_goodness=     7.526 train_neg_goodness=     0.376 \n",
      "[Layer: 2] [ 50] train_pos_goodness=     7.539 train_neg_goodness=     0.374 \n",
      "[Layer: 2] [ 51] train_pos_goodness=     7.551 train_neg_goodness=     0.373 \n",
      "[Layer: 2] [ 52] train_pos_goodness=     7.564 train_neg_goodness=     0.372 \n",
      "[Layer: 2] [ 53] train_pos_goodness=     7.576 train_neg_goodness=     0.370 \n",
      "[Layer: 2] [ 54] train_pos_goodness=     7.589 train_neg_goodness=     0.369 \n",
      "[Layer: 2] [ 55] train_pos_goodness=     7.601 train_neg_goodness=     0.368 \n",
      "[Layer: 2] [ 56] train_pos_goodness=     7.613 train_neg_goodness=     0.366 \n",
      "[Layer: 2] [ 57] train_pos_goodness=     7.625 train_neg_goodness=     0.365 \n",
      "[Layer: 2] [ 58] train_pos_goodness=     7.636 train_neg_goodness=     0.364 \n",
      "[Layer: 2] [ 59] train_pos_goodness=     7.648 train_neg_goodness=     0.363 \n",
      "[Layer: 2] [ 60] train_pos_goodness=     7.659 train_neg_goodness=     0.362 \n",
      "[Layer: 2] [ 61] train_pos_goodness=     7.670 train_neg_goodness=     0.361 \n",
      "[Layer: 2] [ 62] train_pos_goodness=     7.682 train_neg_goodness=     0.359 \n",
      "[Layer: 2] [ 63] train_pos_goodness=     7.692 train_neg_goodness=     0.358 \n",
      "[Layer: 2] [ 64] train_pos_goodness=     7.703 train_neg_goodness=     0.357 \n",
      "[Layer: 2] [ 65] train_pos_goodness=     7.714 train_neg_goodness=     0.356 \n",
      "[Layer: 2] [ 66] train_pos_goodness=     7.725 train_neg_goodness=     0.355 \n",
      "[Layer: 2] [ 67] train_pos_goodness=     7.735 train_neg_goodness=     0.354 \n",
      "[Layer: 2] [ 68] train_pos_goodness=     7.746 train_neg_goodness=     0.353 \n",
      "[Layer: 2] [ 69] train_pos_goodness=     7.756 train_neg_goodness=     0.352 \n",
      "[Layer: 2] [ 70] train_pos_goodness=     7.767 train_neg_goodness=     0.351 \n",
      "[Layer: 2] [ 71] train_pos_goodness=     7.777 train_neg_goodness=     0.350 \n",
      "[Layer: 2] [ 72] train_pos_goodness=     7.788 train_neg_goodness=     0.349 \n",
      "[Layer: 2] [ 73] train_pos_goodness=     7.798 train_neg_goodness=     0.348 \n",
      "[Layer: 2] [ 74] train_pos_goodness=     7.808 train_neg_goodness=     0.347 \n",
      "[Layer: 2] [ 75] train_pos_goodness=     7.818 train_neg_goodness=     0.346 \n",
      "[Layer: 2] [ 76] train_pos_goodness=     7.828 train_neg_goodness=     0.345 \n",
      "[Layer: 2] [ 77] train_pos_goodness=     7.838 train_neg_goodness=     0.344 \n",
      "[Layer: 2] [ 78] train_pos_goodness=     7.849 train_neg_goodness=     0.343 \n",
      "[Layer: 2] [ 79] train_pos_goodness=     7.858 train_neg_goodness=     0.342 \n",
      "[Layer: 2] [ 80] train_pos_goodness=     7.868 train_neg_goodness=     0.342 \n",
      "[Layer: 2] [ 81] train_pos_goodness=     7.878 train_neg_goodness=     0.341 \n",
      "[Layer: 2] [ 82] train_pos_goodness=     7.888 train_neg_goodness=     0.340 \n",
      "[Layer: 2] [ 83] train_pos_goodness=     7.898 train_neg_goodness=     0.339 \n",
      "[Layer: 2] [ 84] train_pos_goodness=     7.907 train_neg_goodness=     0.338 \n",
      "[Layer: 2] [ 85] train_pos_goodness=     7.917 train_neg_goodness=     0.337 \n",
      "[Layer: 2] [ 86] train_pos_goodness=     7.927 train_neg_goodness=     0.336 \n",
      "[Layer: 2] [ 87] train_pos_goodness=     7.936 train_neg_goodness=     0.336 \n",
      "[Layer: 2] [ 88] train_pos_goodness=     7.946 train_neg_goodness=     0.335 \n",
      "[Layer: 2] [ 89] train_pos_goodness=     7.955 train_neg_goodness=     0.334 \n",
      "[Layer: 2] [ 90] train_pos_goodness=     7.964 train_neg_goodness=     0.333 \n",
      "[Layer: 2] [ 91] train_pos_goodness=     7.973 train_neg_goodness=     0.332 \n",
      "[Layer: 2] [ 92] train_pos_goodness=     7.982 train_neg_goodness=     0.332 \n",
      "[Layer: 2] [ 93] train_pos_goodness=     7.991 train_neg_goodness=     0.331 \n",
      "[Layer: 2] [ 94] train_pos_goodness=     8.000 train_neg_goodness=     0.330 \n",
      "[Layer: 2] [ 95] train_pos_goodness=     8.009 train_neg_goodness=     0.329 \n",
      "[Layer: 2] [ 96] train_pos_goodness=     8.018 train_neg_goodness=     0.329 \n",
      "[Layer: 2] [ 97] train_pos_goodness=     8.027 train_neg_goodness=     0.328 \n",
      "[Layer: 2] [ 98] train_pos_goodness=     8.035 train_neg_goodness=     0.327 \n",
      "[Layer: 2] [ 99] train_pos_goodness=     8.044 train_neg_goodness=     0.326 \n",
      "[Layer: 2] [100] train_pos_goodness=     8.053 train_neg_goodness=     0.326 \n"
     ]
    }
   ],
   "source": [
    "metrics = {\n",
    "    \"pos_goodness\": [],\n",
    "    \"neg_goodness\": [],\n",
    "    \"valid_goodness\": [],\n",
    "    \"valid_accuracy\": [],\n",
    "}\n",
    "\n",
    "optims = [optax.adamw(LEARNING_RATE) for _ in range(len(model.layers))]\n",
    "opt_states = [optim.init(eqx.filter(layer, eqx.is_array))\n",
    "              for optim, layer in zip(optims, model.layers)]\n",
    "\n",
    "trained_model, trained_opt_states, metrics = train_greedy(\n",
    "    model, optims, opt_states, metrics=metrics, \n",
    "    threshold=THRESHOLD, batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS, print_every=PRINT_EVERY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trained_model, trained_opt_states, metrics = train(\n",
    "#     trained_model, optims, trained_opt_states, metrics=metrics,\n",
    "#     threshold=THRESHOLD, batch_size=BATCH_SIZE,\n",
    "#     epochs=EPOCHS, print_every=PRINT_EVERY\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 940
    },
    "id": "JErxrnOBoHZt",
    "outputId": "7e46b5ff-beb9-4f17-f52c-a2d267b2179d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('goodness')\n",
    "ax1.plot(metrics[\"pos_goodness\"], label='positive')\n",
    "ax1.plot(metrics[\"valid_goodness\"], label='validation')\n",
    "ax1.plot(metrics[\"neg_goodness\"], label='negative')\n",
    "ax1.axhline(THRESHOLD, linestyle='--', label='threshold', color='red')\n",
    "ax1.tick_params(axis='y')\n",
    "ax1.legend(title='goodness')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('accuracy')\n",
    "ax2.plot(metrics[\"valid_accuracy\"], color='black', label='validation')\n",
    "ax2.tick_params(axis='y')\n",
    "ax2.legend(title='accuracy', loc='center right')\n",
    "ax2.set_ylim([0., 1.])\n",
    "ax2.set_yticks(list(np.linspace(0., 1., 9)) + [max(metrics[\"valid_accuracy\"])])\n",
    "\n",
    "plt.title(f\"FMNIST 784-512-512, softplus, thr={THRESHOLD}, adamw_lr={LEARNING_RATE}, bs={BATCH_SIZE}\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(f'metrics_fmnist_784-512-512_softplus_{THRESHOLD}_adamw_{LEARNING_RATE}_{BATCH_SIZE}.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16.830121994018555, 0.9510799646377563)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_goodness, test_accuracy = evaluate(trained_model, X_test, y_test, BATCH_SIZE)\n",
    "\n",
    "# metrics[\"test_goodness\"] = [test_goodness.item()]\n",
    "# metrics[\"test_accuracy\"] = [test_accuracy.item()]\n",
    "\n",
    "test_goodness.item(), test_accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics[\"batch_size\"] = BATCH_SIZE\n",
    "metrics[\"threshold\"] = THRESHOLD\n",
    "metrics[\"learning_rate\"] = LEARNING_RATE\n",
    "metrics[\"optimizer\"] = \"adamw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(f\"metrics_fmnist_784-512-512_softplus_{THRESHOLD}_adamw_{LEARNING_RATE}_{BATCH_SIZE}.json\", \"w\") as f:\n",
    "    json.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(filename, metrics, model, opt_states):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write((json.dumps(metrics) + \"\\n\").encode())\n",
    "        eqx.tree_serialise_leaves(f, model)\n",
    "        eqx.tree_serialise_leaves(f, opt_states)\n",
    "\n",
    "save_model(f'checkpoint_fmnist_784-512-512_softplus_{THRESHOLD}_adamw_{LEARNING_RATE}_{BATCH_SIZE}.eqx',\n",
    "           metrics, trained_model, trained_opt_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_model(filename):\n",
    "#     with open(filename, \"b\") as f:\n",
    "#         new_metrics = json.loads(f.readling().decode())\n",
    "#         new_model = None"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
